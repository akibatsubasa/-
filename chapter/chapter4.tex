\chapter{楽曲制作}
\section{Melody\_rnnを使用して学習モデルを作成}
\subsection{NoteSequenceの作成}
NoteSequenceとはMIDIデータから作成されるプロトコルバッファである.
プロトコルバッファとはGoogleが2008年にオープンソース化したバイナリベースのデータフォーマットである.
既存の技術としてはXMLやJSONなどのテキストベースのデータフォーマットがあるが,プロトコルバッファはバイナリフォーマットであるので,アプリケーション間でデータ構造の送受信をする際に少ないデータ量ですむという特徴がある.
\begin{table}[h]
\begin{center}
\caption{JSONとプロトコルバッファの比較}
\label{tab:JSONとプロトコルバッファの比較}
\begin{tabular}{|l|c|c|}
\hline
    & プロトコルバッファ & JSON\\ \hline
    \hline
    フォーマット & バイナリベース & テキストベース\\
    \hline
    データ量 & 少ない & 多い \\
    \hline
     &GPU & GeForce GTX 1060\\
    \hline
     &CUDA & CUDA(9),cuDNN(7.4.2)\\
    \hline
     &ライブラリ & TensorFlow(1.12.0),magenta(0.5.0)\\
    \hline
\end{tabular}
\end{center}
\end{table}\\
　NoteSequenceの作成は以下に示すコマンドで作成できる.\\
　--input\_dirで学習させるMIDIデータのディレクトリの絶対パスを指定し,--output\_fileでNotesequenceの出力先のディレクトリを指定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
    convert\_dir\_to\_note\_sequences \
    --input\_dir=\$INPUT\_DIRECTORY \
    --output\_file=\$SEQUENCES\_TFRECORD \
    --recursive
\end{lstlisting}
\newpage
次に作成したNoteSequenceのデータセットを学習用と評価用に分割するために以下に示すのコマンドを実行する.\\
　--configで使用するRNNを指定する.--input\_dirでNoteSequenceの絶対パスを指定し,--output\_fileで分割したNotesequenceの出力先のディレクトリを指定する.
--eval\_ratioでNotesequenceのデータを何パーセント学習用に用いるかを指定する.コマンドの場合は10\%が学習用のデータになる.
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
melody_rnn_create_dataset \
--config=<one of 'basic_rnn', 'lookback_rnn', or 'attention_rnn'> \
--input=/tmp/notesequences.tfrecord \
--output_dir=/tmp/melody_rnn/sequence_examples \
--eval_ratio=0.10
\end{lstlisting}
\subsection{basic\_rnnを用いて学習を開始}
作成したNoteSequenceから学習モデルを作成するために以下のコマンドを実行する.\\
--configで学習に使用するbasic\_rnnを指定,--rundirで学習のために用意したNotesequenceを指定し,--sequence\_examplefileで学習モデルの出力先のディレクトリを指定する.
--hparamsでメモリの使用量を指定し,--rnn\_layer\_sizeで中間層のノード数を指定し,--num\_trainingstepsで学習回数を設定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
melody_rnn_train \
--config=basic_rnn \
--run_dir=/tmp/melody_rnn/logdir/run1 \
--sequence_example_file=/tmp/melody_rnn/training_melodies.tfrecord \
--hparams="batch_size=64,rnn_layer_sizes=[64,64]" \
--num_training_steps=20000
\end{lstlisting}
\newpage
\subsection{lookback\_rnnを用いて学習を開始}
作成したNoteSequenceから学習モデルを作成するために以下のコマンドを実行する.\\
　--configで学習に使用するlookback\_rnnを指定,--rundirで学習のために用意したNotesequenceを指定し,--sequence\_examplefileで学習モデルの出力先のディレクトリを指定する.
--hparamsでメモリの使用量を指定し,--rnn\_layer\_sizeで中間層のノード数を指定し,--num\_trainingstepsで学習回数を設定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
melody_rnn_train \
--config=lookback_rnn \
--run_dir=/tmp/melody_rnn/logdir/run1 \
--sequence_example_file=/tmp/melody_rnn/training_melodies.tfrecord \
--hparams="batch_size=64,rnn_layer_sizes=[64,64]" \
--num_training_steps=20000
\end{lstlisting}
\subsection{attention\_rnnを用いて学習を開始}
作成したNoteSequenceから学習モデルを作成するために以下のコマンドを実行する.\\
　--configで学習に使用するattention\_rnnを指定,--rundirで学習のために用意したNotesequenceを指定し,--sequence\_examplefileで学習モデルの出力先のディレクトリを指定する.
--hparamsでメモリの使用量を指定し,--rnn\_layer\_sizeで中間層のノード数を指定し,--num\_trainingstepsで学習回数を設定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
melody_rnn_train \
--config=attention_rnn \
--run_dir=/tmp/melody_rnn/logdir/run1 \
--sequence_example_file=/tmp/melody_rnn/training_melodies.tfrecord \
--hparams="batch_size=64,rnn_layer_sizes=[64,64]" \
--num_training_steps=20000
\end{lstlisting}
\newpage
\subsection{音楽データの作成}
以下に示すコマンドで学習モデルに入力する.\\
　--configで学習に使用するattention\_rnnを指定,--rundirで学習済みのモデルを指定し,--output\_dirで音楽データの出力先のディレクトリを指定する.
--num\_outputsで生成する音楽データの個数を指定し,--num\_stepsで
--hparamsでメモリの使用量を指定し,--rnn\_layer\_sizeで中間層のノード数を指定し,--primer\_melodyで学習モデルに入力する最初の音程をMIDIの形式で指定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
    melody_rnn_generate \
    --config=attention_rnn \
    --run_dir=/tmp/melody_rnn/logdir/run1 \
    --output_dir=/tmp/melody_rnn/generated \
    --num_outputs=10 \
    --num_steps=128 \
    --hparams="batch_size=64,rnn_layer_sizes=[64,64]" \
    --primer_melody="[60]"
\end{lstlisting}
\subsection{事前に学習済のモデルを使用}
また,Magendaのプロジェクトにすでに学習済のモデルが存在するのでそれを使用して音楽データを作成することもできる.
生成にはmagバンドファイルが必要になるのでmagendaのGithubに公開されているので,それをダウンロードしてくる.
その後以下に示すコマンドを実行する事で生成することができる.\\
　--configで学習に使用する学習モデルを指定,--rundirで学習済みのモデルを指定し,--output\_dirで音楽データの出力先のディレクトリを指定する.
--num\_outputsで生成する音楽データの個数を指定し,--num\_stepsで
--hparamsでメモリの使用量を指定し,--rnn\_layer\_sizeで中間層のノード数を指定し,--primer\_melodyで学習モデルに入力する最初の音程をMIDIの形式で指定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
    melody_rnn_generate \
    --config=${CONFIG} \
    --bundle_file=${BUNDLE_PATH} \
    --output_dir=/tmp/melody_rnn/generated \
    --num_outputs=10 \
    --num_steps=128 \
    --primer_melody="[60]"
\end{lstlisting}
\newpage
\section{Polyphony\_rnnを使用して学習モデルを作成}
PolyphonyRNNを使用してする手順としては,大まかな流れは同じであるが--configで使用するRNNを指定する必要がないという違いがある
\subsection{NoteSequenceの作成}
NoteSequenceの作成は以下に示すコマンドで作成できる.\\
--input\_dirで学習させるMIDIデータのディレクトリの絶対パスを指定し,--output\_fileでNotesequenceの出力先のディレクトリを指定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
    convert\_dir\_to\_note\_sequences \
    --input\_dir=\$INPUT\_DIRECTORY \
    --output\_file=\$SEQUENCES\_TFRECORD \
    --recursive
\end{lstlisting}
　次に作成したNoteSequenceのデータセットを学習用と評価用に分割するために以下に示すのコマンドを実行する.\\
--input\_dirでNoteSequenceの絶対パスを指定し,--output\_fileで分割したNotesequenceの出力先のディレクトリを指定する.
--eval\_ratioでNotesequenceのデータを何パーセント学習用に用いるかを指定する.コマンドの場合は10\%が学習用のデータになる.
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
    polyphony_rnn_create_dataset \
    --input=/tmp/notesequences.tfrecord \
    --output_dir=/tmp/polyphony_rnn/sequence_examples \
    --eval_ratio=0.10
    \end{lstlisting}
\subsection{学習の開始}
作成したNoteSequenceから学習モデルを作成するために以下のコマンドを実行する.\\
--configで学習に使用する学習モデルを指定,--rundirで学習のために用意したNotesequenceを指定し,--sequence\_examplefileで学習モデルの出力先のディレクトリを指定する.
--hparamsでメモリの使用量を指定し,--rnn\_layer\_sizeで中間層のノード数を指定し,--num\_trainingstepsで学習回数を設定する.\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
polyphony_rnn_train \
--run_dir=/tmp/polyphony_rnn/logdir/run1 \
--sequence_example_file=/tmp/polyphony_rnn/training_tracks.tfrecord \
--hparams="batch_size=64,rnn_layer_sizes=[64,64]" \
--num_training_steps=20000
\end{lstlisting}
\subsection{音楽データの作成}
以下に示すコマンドで学習モデルに入力する.\\
--configで学習に使用する学習モデルを指定,--rundirで学習済みのモデルを指定し,--output\_dirで音楽データの出力先のディレクトリを指定する.
--num\_outputsで生成する音楽データの個数を指定し,--num\_stepsで
--hparamsでメモリの使用量を指定し,--rnn\_layer\_sizeで中間層のノード数を指定し,--primer\_melodyで学習モデルに入力する最初の音程をMIDIの形式で指定する.(図\ref{fig:MIDIと音階}参照)\\
\begin{lstlisting}[basicstyle=\ttfamily\footnotesize,frame=single]
    polyphony_rnn_generate \
    --run_dir=/tmp/polyphony_rnn/logdir/run1 \
    --hparams="batch_size=64,rnn_layer_sizes=[64,64]" \
    --output_dir=/tmp/polyphony_rnn/generated \
    --num_outputs=10 \
    --num_steps=128 \
    --primer_pitches="[67,64,60]" \
    --condition_on_primer=true \
    --inject_primer_during_generation=false
\end{lstlisting}